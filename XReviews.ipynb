{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Es98pwciqF07",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paso 1: Importar las bibliotecas tweepy y pandas\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ct7JtEo6qHY0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "bearer_token = os.getenv(\"bearer_token\")\n",
    "url = 'https://api.twitter.com/2/tweets'  # Un endpoint de ejemplo de la API v2\n",
    "headers = {\n",
    "    'Authorization': bearer_token,\n",
    "}\n",
    "client = tweepy.Client(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Límite de tasa total: None\n",
      "Solicitudes restantes: None\n",
      "Límite de tasa se restablece en: None\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(url, headers=headers)\n",
    "print(\"Límite de tasa total:\", response.headers.get('x-rate-limit-limit'))\n",
    "print(\"Solicitudes restantes:\", response.headers.get('x-rate-limit-remaining'))\n",
    "print(\"Límite de tasa se restablece en:\", response.headers.get('x-rate-limit-reset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 tweets recolectados y guardados en \"New_TWEETS/tweets_\"First Horizon Bank\" OR #FirstHorizonBank.csv\"\n",
      "50 tweets recolectados y guardados en \"New_TWEETS/tweets_\"Fifth Third Bank\" OR #FifthThirdBank.csv\"\n",
      "50 tweets recolectados y guardados en \"New_TWEETS/tweets_\"Citizens Bank\" OR #CitizensBank.csv\"\n",
      "50 tweets recolectados y guardados en \"New_TWEETS/tweets_\"MandT Bank\" OR #MandTBank.csv\"\n"
     ]
    }
   ],
   "source": [
    "exclude_retweets = '-is:retweet'\n",
    "tweet_amount = 50      \n",
    "language = \"en\"          \n",
    "\n",
    "#Nuevos Bancos\n",
    "terms=['\"First Horizon Bank\" OR #FirstHorizonBank',\n",
    "       '\"Fifth Third Bank\" OR #FifthThirdBank',\n",
    "       '\"Citizens Bank\" OR #CitizensBank',\n",
    "       '\"MandT Bank\" OR #MandTBank']\n",
    "\n",
    "'''\n",
    "terms=['\"Banking Circle US\" OR #BankingCircleUS',\n",
    "       '\"Bankwell Bank\" OR #BankwellBank',\n",
    "       '\"Chelsea Groton Bank\" OR #ChelseaGrotonBank',\n",
    "       '\"Dime Bank\" OR #DimeBank','\"DR Bank\" OR #DRBank',\n",
    "       '\"Eastern Connecticut Savings Bank\" OR #EasternConnecticutSavingsBank',\n",
    "       '\"Essex Savings Bank\" OR #EssexSavingsBank',\n",
    "       '\"Fairfield County Bank\" OR #FairfieldCountyBank',\n",
    "       '\"Fieldpoint Private Bank & Trust\" OR #FieldpointPrivateBankANDTrust',\n",
    "       '\"First Bank of Greenwich\" OR #FirstBankofGreenwich',\n",
    "       '\"First County Bank\" OR #FirstCountyBank',\n",
    "       '\"Guilford Savings Bank\" OR #GuilfordSavingsBank',\n",
    "       '\"Ion Bank\" OR #IonBank',\n",
    "       '\"Jewett City Savings Bank\" OR #JewettCitySavingsBank',\n",
    "       '\"Liberty Bank\" OR #LibertyBank',\n",
    "       '\"Milford Bank\" OR #MilfordBank',\n",
    "       '\"New Haven Bank\" OR #NewHavenBank',\n",
    "       '\"Newtown Savings Bank\" OR #NewtownSavingsBank',\n",
    "       '\"Northwest Community Bank\" OR #NorthwestCommunityBank',\n",
    "       '\"Savings Bank of Danbury\" OR #SavingsBankofDanbury',\n",
    "       '\"Stafford Savings Bank\" OR #StaffordSavingsBank',\n",
    "       '\"Thomaston Savings Bank\" OR #ThomastonSavingsBank',\n",
    "       '\"Torrington Savings Bank\" OR #TorringtonSavingsBank',\n",
    "       '\"Union Savings Bank\" OR #UnionSavingsBank']'''\n",
    "\n",
    "for search_term in terms:\n",
    "    query = f'{search_term} {exclude_retweets} lang:{language}'\n",
    "    tweets_data = []\n",
    "    tweets = client.search_recent_tweets(query=query,max_results=tweet_amount)#https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent\n",
    "\n",
    "    if tweets.data is not None:    \n",
    "        for tweet in tweets.data:  # Iterar a través de cada tweet en la respuesta de la búsqueda de tweets\n",
    "            tweets_data.append({   # Añadir un diccionario con los datos del tweet al arreglo tweets_data\n",
    "                #'id': tweet.id,                               # Almacenar el ID único del tweet\n",
    "                #'author_id': tweet.author_id,                 # Almacenar el ID del autor del tweet\n",
    "                #'conversation_id': tweet.conversation_id,     # Almacenar el ID de la conversación asociada al tweet\n",
    "                'created_at': tweet.created_at,               # Almacenar la fecha y hora de creación del tweet\n",
    "                'text': tweet.text,                           # Almacenar el texto completo del tweet\n",
    "                # Acceder al sub-diccionario 'public_metrics' y almacenar el conteo de retweets\n",
    "                #'retweets': tweet.public_metrics['retweet_count'],\n",
    "                # Almacenar el número de respuestas que ha recibido el tweet\n",
    "                #'replies': tweet.public_metrics['reply_count'],\n",
    "                # Almacenar el número de 'me gusta' que ha recibido el tweet\n",
    "                #'likes': tweet.public_metrics['like_count'],\n",
    "                # Almacenar el número de veces que el tweet ha sido citado\n",
    "                #'quotes': tweet.public_metrics['quote_count']\n",
    "                # https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet\n",
    "            })    \n",
    "        tweets_df = pd.DataFrame(tweets_data)\n",
    "        csv_file_name = f\"New_TWEETS/tweets_{search_term}.csv\"\n",
    "        tweets_df.to_csv(csv_file_name, index=False)\n",
    "        print(f'{len(tweets_data)} tweets recolectados y guardados en \"{csv_file_name}\"')\n",
    "        time.sleep(20)\n",
    "    else:\n",
    "        print(f\"No se encontraron datos para la búsqueda: {search_term}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-prMsRv0qJYp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#terms=['\"DR Bank\" OR #DRBank',]\n",
    "search_term = '\"Chelsea Groton Bank\" OR #ChelseaGrotonBank' # Ejemplo de término de búsqueda\n",
    "exclude_retweets = '-is:retweet'\n",
    "tweet_amount = 50       # Cantidad de tweets que deseas recuperar\n",
    "language = \"en\"          # Código del idioma deseado (ejemplo: 'es' para español)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'{search_term} {exclude_retweets} lang:{language}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Gc3jjWfAqLme",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paso 5: Crear una lista vacía para almacenar los tweets\n",
    "tweets_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gfOeAvUoqMke",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paso 6: Realizar la búsqueda utilizando la API v2\n",
    "#query = f'{search_term} lang:{language}' #https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\n",
    "tweets = client.search_recent_tweets(query=query, max_results=tweet_amount) #https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "nJkfB0dxqOBq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paso 7: Procesar los resultados y almacenar los datos de interés en el dataset\n",
    "for tweet in tweets.data:  # Iterar a través de cada tweet en la respuesta de la búsqueda de tweets\n",
    "    tweets_data.append({   # Añadir un diccionario con los datos del tweet al arreglo tweets_data\n",
    "        #'id': tweet.id,                               # Almacenar el ID único del tweet\n",
    "        #'author_id': tweet.author_id,                 # Almacenar el ID del autor del tweet\n",
    "        #'conversation_id': tweet.conversation_id,     # Almacenar el ID de la conversación asociada al tweet\n",
    "        'created_at': tweet.created_at,               # Almacenar la fecha y hora de creación del tweet\n",
    "        'text': tweet.text,                           # Almacenar el texto completo del tweet\n",
    "        # Acceder al sub-diccionario 'public_metrics' y almacenar el conteo de retweets\n",
    "        #'retweets': tweet.public_metrics['retweet_count'],\n",
    "        # Almacenar el número de respuestas que ha recibido el tweet\n",
    "        #'replies': tweet.public_metrics['reply_count'],\n",
    "        # Almacenar el número de 'me gusta' que ha recibido el tweet\n",
    "        #'likes': tweet.public_metrics['like_count'],\n",
    "        # Almacenar el número de veces que el tweet ha sido citado\n",
    "        #'quotes': tweet.public_metrics['quote_count']\n",
    "        # https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "V5ayjPC_qPAw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paso 8: Crear un DataFrame con los datos recolectados\n",
    "tweets_df = pd.DataFrame(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3i0BWzkqP3o",
    "outputId": "ea8bb505-65a4-4c56-e3e6-36482c95b748",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 tweets recolectados y guardados en \"tweets_\"DR Bank\" OR #DRBank.csv\"\n"
     ]
    }
   ],
   "source": [
    "# Paso 9: Guardar los datos en un archivo CSV\n",
    "csv_file_name = f\"TWEETS/tweets_{search_term}.csv\"\n",
    "tweets_df.to_csv(csv_file_name, index=False)\n",
    "print(f'{len(tweets_data)} tweets recolectados y guardados en \"{csv_file_name}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "62g3Bb9GTR0h",
    "outputId": "d9697d0d-c4ba-428c-b0b2-c851f6d115a9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     RT @LolyLoly_15: Aroma Duit Baru, yg keluar dr...\n",
       "1     Ape doh bank mintak dkt audit draft sijil baki...\n",
       "2     @BNICustomerCare @BNI fitur terima dana QRIS B...\n",
       "3     @Nataputra12174 @kadrunmampos Tetangga saya ke...\n",
       "4     @jjkcollector biasanya kepotong kalo dr bank k...\n",
       "                            ...                        \n",
       "93    RT @tinvsel: Hallo guys mau info, kalian jgn m...\n",
       "94    @worksfess Satu-satunya yg bisa dipercaya cuma...\n",
       "95    @joshuartistik Benerrrr, tp ini td aneh bgt da...\n",
       "96    @6jwonwoo Klo dr bank ke spay kena Chi dan pas...\n",
       "97    @sunchaniep sendiri ajaa cepet kok, dr bank jg...\n",
       "Name: text, Length: 98, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
